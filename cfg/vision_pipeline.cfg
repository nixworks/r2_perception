#!/usr/bin/env python
PACKAGE = "r2_perception"

from dynamic_reconfigure.parameter_generator_catkin import *

gen = ParameterGenerator()

gen.add("fovy",double_t,0,"vertical field-of-view (radians)",0.62,0.0001,10.0)
gen.add("aspect",double_t,0,"aspect ration (horz. pixels / vert. pixels)",1.3333,0.2,5.0)
gen.add("rotate",double_t,0,"optical axis rotation (degrees)",0.0,-180.0,180.0)
gen.add("cutout",double_t,0,"camera image cut-out factor",1.0,0.0,1.0)
gen.add("face_height",double_t,0,"height of real face rectangle (m)",0.155,0.0,1.0)
gen.add("work_width",int_t,0,"detection algorithm width (pixels)",320,0,10000)
gen.add("work_height",int_t,0,"detection algorithm height (pixels)",240,10000)
gen.add("haar_scale_factor",double_t,0,"Haar cascade scale factor",1.1,0.0,10.0)
gen.add("haar_min_width",int_t,0,"Haar cascade minimum width (pixels)",30,0,1000)
gen.add("haar_min_height",int_t,0,"Haar cascade minimum height (pixels)",30,0,1000)
gen.add("ittikoch_reduced_width",int_t,0,"Itti&Koch reduced sum width (pixels)",80,0,10000)
gen.add("ittikoch_reduced_height",int_t,0,"Itti&Koch reduced sum height (pixels)",80,0,10000)
gen.add("ittikoch_gaussian_size",int_t,0,"Itti&Koch gaussian size (pixels)",13,1,101)
gen.add("ittikoch_motion_factor",double_t,0,"Itti&Koch motion feature weight",0.5,0.0,1.0)
gen.add("ittikoch_color_factor",double_t,0,"Itti&Koch color feature weigth",0.2,0.0,1.0)
gen.add("ittikoch_contrast_factor",double_t,0,"Itti&Koch contrast feature weight",0.1,0.0,1.0)
gen.add("ittikoch_num_points",int_t,0,"Itti&Koch number of output points",5,0,100)
gen.add("ittikoch_eraser_radius",int_t,0,"Itti&Koch eraser radius",10,0,100)
gen.add("face_regression_flag",bool_t,0,"use linear regression for face estimation",True)
gen.add("hand_regression_flag",bool_t,0,"use linear regression for hand estimation",True)
gen.add("saliency_regression_flag",bool_t,0,"use linear regression for saliency estimation",False)
gen.add("face_fuse_distance",double_t,0,"distance at which two faces are fused (meters)",0.2,0.0,2.0)
gen.add("hand_fuse_distance",double_t,0,"distance at which two hands are fused (meters)",0.1,0.0,2.0)
gen.add("saliency_fuse_distance",double_t,0,"distance at which two saliency vectors are fused (TBD)",0.001,0.0,2.0)
gen.add("min_face_confidence",double_t,0,"minimum confidence for a face to get reported",0.6,0.0,1.0)
gen.add("min_hand_confidence",double_t,0,"minimum confidence for a hand to get reported",0.6,0.0,1.0)
gen.add("min_saliency_confidence",double_t,0,"minimum confidence for a saliency vector to get reported",0.6,0.0,1.0)
gen.add("face_keep_time",double_t,0,"time to keep track of previous faces (sec.)",1.0,0.0,10.0)
gen.add("hand_keep_time",double_t,0,"time to keep track of previous hands (sec.)",0.5,0.0,10.0)
gen.add("saliency_keep_time",double_t,0,"time to keep track of previous saliency vectors (sec).",0.2,0.0,10.0)
gen.add("full_face_points",int_t,0,"number of consecutive faces for full confidence",3,0,100)
gen.add("full_hand_points",int_t,0,"number of consecutive hands for full confidence",3,0,100)
gen.add("full_saliency_points",int_t,0,"number of consecutive saliency vectors for full confidence",2,0,100)
gen.add("pipeline_rate",double_t,0,"rate at which observations are sent to fusion (Hz)",20.0,0.0,100.0)
gen.add("detect_rate",double_t,0,"rate at which detection algorithms are run (Hz)",10.0,0.0,100.0)
gen.add("face_rate_divider",int_t,0,"divider at which face detection is run",1,0,100)
gen.add("hand_rate_divider",int_t,0,"divider at which hand detection is run",1,0,100)
gen.add("saliency_rate_divider",int_t,0,"divider at which saliency detection is run",1,0,100)
gen.add("visualize_candidates_flag",bool_t,0,"show candidates from each pipeline at visualization",True)
gen.add("debug_face_detect_flag",bool_t,0,"show extra window with face detection algorithm",False)
gen.add("debug_hand_detect_flag",bool_t,0,"show extra window with hand detection algorithm",False)
gen.add("debug_saliency_detect_flag",bool_t,0,"show extra window with saliency detection algorithm",False)
gen.add("debug_vision_flag",bool_t,0,"show extra window with combined faces, hands and saliency",False)

exit(gen.generate(PACKAGE,"vision_pipeline","vision_pipeline"))
