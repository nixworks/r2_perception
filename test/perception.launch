<?xml version="1.0" encoding="UTF-8"?>
<launch>

	<arg name="name"/>

	<!-- while we're still using Blender in the old backend, so update transformations accordingly -->
	<!-- gather Blender PAU messages and generate joint_states, and update tf from that -->
	<node name="gather_pau_states" type="gather_pau_states.py" pkg="r2_perception"/>
	<node name="robot_state_publisher" type="state_publisher" pkg="robot_state_publisher"/>

	<!-- geometry description -->
	<param name="robot_description" textfile="$(find r2_perception)/test/robot.urdf"/>

	<!-- where to store temporaries for face analysis -->
	<param name="face_analysis_temp_dir" value="$(find r2_perception)/test"/>

	<!-- whether or not to store thumbnails -->
	<param name="store_thumbs_flag" value="false"/>

	<!-- directory to store face thumbnails -->
	<param name="thumbs_dir" value="$(find r2_perception)/test"/>

	<!-- face thumbnail extension -->
	<param name="thumbs_ext" value="png"/>

	<!-- whether or not to store sounds -->
	<param name="store_sounds_flag" value="false"/>

	<!-- directory to store sounds -->
	<param name="sounds_dir" value="$(find r2_perception)/test"/>

	<!-- filename for Haar cascade -->
	<param name="haar_cascade_filename" value="$(find r2_perception)/test/haarcascade_frontalface_alt.xml"/>

	<!-- visualization via RViz -->
	<param name="visualize_flag" value="true"/>

	<!-- size of face thumbnail -->
	<param name="thumb_width" value="64"/>
	<param name="thumb_height" value="64"/>

	<!-- /robot -->
	<group ns="/$(arg name)">

		<!-- perception subsystem -->
		<group ns="perception">

			<!-- load all parameters from yaml -->
			<rosparam file="$(find r2_perception)/test/perception.yaml" command="load"/>

			<!-- left eye camera -->
			<!--<group ns="lefteye">
				<node name="camera" type="usb_cam_node" pkg="usb_cam">
					<param name="video_device" value="/dev/video1"/>
					<param name="pixel_format" value="yuyv"/>
					<param name="image_width" value="320"/>
					<param name="image_height" value="240"/>
				</node>
				<node name="detect" type="detect_faces_haar_hands_saliency_ittikoch.py" pkg="r2_perception"/>
				<node name="face_analysis" type="face_analysis_openbr.py" pkg="r2_perception"/>
				<node name="vision_pipeline" type="vision_pipeline.py" pkg="r2_perception"/>
			</group>-->

			<!-- right eye camera -->
			<!--<group ns="righteye">
				<node name="camera" type="usb_cam_node" pkg="usb_cam">
					<param name="video_device" value="/dev/video2"/>
					<param name="pixel_format" value="yuyv"/>
					<param name="image_width" value="320"/>
					<param name="image_height" value="240"/>
				</node>
				<node name="detect" type="detect_faces_haar_hands_saliency_ittikoch.py" pkg="r2_perception"/>
				<node name="face_analysis" type="face_analysis.py" pkg="r2_perception"/>
				<node name="vision_pipeline" type="vision_pipeline.py" pkg="r2_perception"/>
			</group>-->

			<!-- RealSense camera -->
			<!--<group ns="realsense">
				<node name="realsense_param_proxy" type="realsense_param_proxy.py" pkg="r2_perception"/>
				<node name="face_analysis" type="face_analysis_openbr.py" pkg="r2_perception"/>
				<node name="vision_pipeline" type="vision_pipeline.py" pkg="r2_perception"/>
			</group>-->

			<!-- wideangle camera -->
			<group ns="wideangle">
				<node name="camera" type="usb_cam_node" pkg="usb_cam">
					<param name="video_device" value="/dev/video0"/>
					<param name="pixel_format" value="yuyv"/>
					<param name="image_width" value="320"/>
					<param name="image_height" value="240"/>
				</node>
				<node name="detect" type="detect_faces_haar_hands_saliency_ittikoch.py" pkg="r2_perception"/>
				<node name="face_analysis" type="face_analysis_openbr.py" pkg="r2_perception"/>
				<node name="vision_pipeline" type="vision_pipeline.py" pkg="r2_perception"/>
			</group>

			<!-- Acoustic Magic microphone array -->
			<!--<group ns="acousticmagic">
				<param name="device" value="hw:2,0"/>
				<param name="port" value="/dev/ttyUSB0"/>
				<node name="detect_sound" type="detect_sound_hyst.py" pkg="r2_perception"/>
				<node name="speech_to_text_google" type="speech_to_text.py" pkg="r2_perception"/>
				<node name="hearing_pipeline" type="hearing_pipeline.py" pkg="r2_perception"/>
			</group>-->

			<!-- handheld microphone -->
			<!--<group ns="handheld">
				<param name="device" value="hw:1,0"/>
				<param name="port" value="/dev/ttyUSB0"/>
				<node name="detect_sound" type="detect_sound_hyst.py" pkg="r2_perception"/>
				<node name="speech_to_text_google" type="speech_to_text.py" pkg="r2_perception"/>
				<node name="hearing_pipeline" type="hearing_pipeline.py" pkg="r2_perception"/>
			</group>-->

			<!-- fusion node -->
			<param name="fusion_rate" value="20.0"/>
			<node name="fusion" type="fusion.py" pkg="r2_perception"/>

			<!-- visualization of perception/input/sensor fusion -->
			<node name="rviz" type="rviz" pkg="rviz" args="-d $(find r2_perception)/test/urdf.rviz"/>

		</group>

	</group>

</launch>
